{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exemplo Completo - Rede Neural para Classificação de Imagens\n",
    "\n",
    "Este notebook demonstra passo a passo como usar o projeto de redes neurais.\n",
    "\n",
    "## Conteúdo:\n",
    "1. Configuração do ambiente\n",
    "2. Carregamento de dados\n",
    "3. Exploração e visualização\n",
    "4. Preprocessamento\n",
    "5. Criação do modelo\n",
    "6. Treinamento\n",
    "7. Avaliação\n",
    "8. Salvamento e carregamento do modelo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Configuração do Ambiente"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importações necessárias\n",
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "# Adiciona o diretório src ao path\n",
    "sys.path.append(os.path.join(os.path.dirname(os.getcwd()), 'src'))\n",
    "\n",
    "# Importa nossos módulos\n",
    "from data_loader import (\n",
    "    carregar_mnist, carregar_fashion_mnist, carregar_cifar10,\n",
    "    preprocessar_dados, dividir_validacao\n",
    ")\n",
    "from model import (\n",
    "    criar_modelo_simples, criar_modelo_cnn,\n",
    "    compilar_modelo, resumo_modelo\n",
    ")\n",
    "from train import (\n",
    "    criar_callbacks, treinar_modelo,\n",
    "    plotar_historico\n",
    ")\n",
    "from evaluate import (\n",
    "    avaliar_modelo, fazer_predicoes,\n",
    "    matriz_confusao, visualizar_predicoes\n",
    ")\n",
    "\n",
    "# Configurações\n",
    "%matplotlib inline\n",
    "plt.style.use('seaborn-v0_8-darkgrid')\n",
    "\n",
    "# Verifica GPU\n",
    "print(f\"TensorFlow versão: {tf.__version__}\")\n",
    "print(f\"GPUs disponíveis: {len(tf.config.list_physical_devices('GPU'))}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Carregamento de Dados\n",
    "\n",
    "Vamos carregar o dataset MNIST como exemplo. Você pode trocar facilmente por outros datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Carrega o dataset (escolha um)\n",
    "# (x_train, y_train), (x_test, y_test) = carregar_mnist()\n",
    "(x_train, y_train), (x_test, y_test) = carregar_fashion_mnist()\n",
    "# (x_train, y_train), (x_test, y_test) = carregar_cifar10()\n",
    "\n",
    "# Informações sobre o dataset\n",
    "print(f\"\\nFormato dos dados:\")\n",
    "print(f\"  x_train: {x_train.shape}\")\n",
    "print(f\"  y_train: {y_train.shape}\")\n",
    "print(f\"  x_test: {x_test.shape}\")\n",
    "print(f\"  y_test: {y_test.shape}\")\n",
    "print(f\"\\nTipo de dados: {x_train.dtype}\")\n",
    "print(f\"Valores mín/máx: {x_train.min()}/{x_train.max()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Exploração e Visualização"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualiza algumas amostras\n",
    "fig, axes = plt.subplots(2, 5, figsize=(12, 5))\n",
    "axes = axes.ravel()\n",
    "\n",
    "# Para Fashion-MNIST\n",
    "class_names = ['Camiseta', 'Calça', 'Suéter', 'Vestido', 'Casaco',\n",
    "               'Sandália', 'Camisa', 'Tênis', 'Bolsa', 'Bota']\n",
    "\n",
    "for i in range(10):\n",
    "    idx = np.random.randint(0, len(x_train))\n",
    "    img = x_train[idx]\n",
    "    label = y_train[idx]\n",
    "    \n",
    "    axes[i].imshow(img, cmap='gray')\n",
    "    axes[i].set_title(f'{class_names[label]} ({label})')\n",
    "    axes[i].axis('off')\n",
    "\n",
    "plt.suptitle('Amostras do Dataset', fontsize=16)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Distribuição das classes\n",
    "unique, counts = np.unique(y_train, return_counts=True)\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.bar(unique, counts)\n",
    "plt.xlabel('Classe')\n",
    "plt.ylabel('Quantidade')\n",
    "plt.title('Distribuição das Classes no Conjunto de Treino')\n",
    "plt.xticks(unique, [class_names[i] for i in unique], rotation=45)\n",
    "plt.grid(axis='y', alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"Classes balanceadas: {np.allclose(counts, counts[0])}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Preprocessamento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocessa os dados\n",
    "x_train_prep, x_test_prep = preprocessar_dados(\n",
    "    x_train, x_test,\n",
    "    normalizar=True,\n",
    "    expandir_dims=True  # Para CNN\n",
    ")\n",
    "\n",
    "# Divide em treino/validação\n",
    "x_train_final, y_train_final, x_val, y_val = dividir_validacao(\n",
    "    x_train_prep, y_train,\n",
    "    val_split=0.1\n",
    ")\n",
    "\n",
    "print(f\"\\nDados após preprocessamento:\")\n",
    "print(f\"  Treino: {x_train_final.shape}\")\n",
    "print(f\"  Validação: {x_val.shape}\")\n",
    "print(f\"  Teste: {x_test_prep.shape}\")\n",
    "print(f\"\\nValores mín/máx após normalização: {x_train_final.min():.2f}/{x_train_final.max():.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Criação do Modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define parâmetros do modelo\n",
    "input_shape = x_train_final.shape[1:]  # (28, 28, 1) para MNIST/Fashion\n",
    "num_classes = 10\n",
    "\n",
    "# Cria o modelo (escolha um)\n",
    "# modelo = criar_modelo_simples(input_shape, num_classes)\n",
    "modelo = criar_modelo_cnn(input_shape, num_classes)\n",
    "\n",
    "# Compila o modelo\n",
    "modelo = compilar_modelo(\n",
    "    modelo,\n",
    "    learning_rate=0.001,\n",
    "    loss='sparse_categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "# Mostra resumo do modelo\n",
    "resumo_modelo(modelo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualiza arquitetura do modelo\n",
    "tf.keras.utils.plot_model(\n",
    "    modelo,\n",
    "    to_file='../results/model_architecture.png',\n",
    "    show_shapes=True,\n",
    "    show_layer_names=True,\n",
    "    rankdir='TB',\n",
    "    dpi=100\n",
    ")\n",
    "\n",
    "from IPython.display import Image\n",
    "Image('../results/model_architecture.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Treinamento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cria callbacks\n",
    "callbacks = criar_callbacks(\n",
    "    model_dir='../models/notebook_model',\n",
    "    patience=5,\n",
    "    monitor='val_loss'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Treina o modelo\n",
    "history = treinar_modelo(\n",
    "    modelo,\n",
    "    x_train_final, y_train_final,\n",
    "    x_val, y_val,\n",
    "    epochs=15,  # Reduzido para demonstração\n",
    "    batch_size=32,\n",
    "    callbacks=callbacks\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualiza o histórico de treinamento\n",
    "plotar_historico(history)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Avaliação"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Avalia no conjunto de teste\n",
    "test_loss, test_accuracy = avaliar_modelo(modelo, x_test_prep, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Faz predições\n",
    "y_pred_probs, y_pred = fazer_predicoes(modelo, x_test_prep)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Matriz de confusão\n",
    "matriz_confusao(y_test, y_pred, class_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualiza algumas predições\n",
    "visualizar_predicoes(\n",
    "    modelo,\n",
    "    x_test_prep[:100],  # Primeiras 100 amostras\n",
    "    y_test[:100],\n",
    "    y_pred[:100],\n",
    "    num_amostras=16,\n",
    "    class_names=class_names\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Salvamento e Carregamento do Modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Salva o modelo\n",
    "from model import salvar_modelo, carregar_modelo\n",
    "\n",
    "modelo_path = '../models/notebook_model/modelo_treinado.h5'\n",
    "salvar_modelo(modelo, modelo_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Carrega o modelo salvo\n",
    "modelo_carregado = carregar_modelo(modelo_path)\n",
    "\n",
    "# Testa se funciona\n",
    "test_loss_2, test_acc_2 = avaliar_modelo(modelo_carregado, x_test_prep[:100], y_test[:100])\n",
    "print(f\"\\nModelo carregado funcionando corretamente!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exemplo: Fazendo Predição em Uma Única Imagem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pega uma imagem aleatória\n",
    "idx = np.random.randint(0, len(x_test))\n",
    "imagem = x_test_prep[idx:idx+1]  # Mantém dimensão do batch\n",
    "label_real = y_test[idx]\n",
    "\n",
    "# Faz a predição\n",
    "predicao = modelo.predict(imagem)\n",
    "classe_predita = np.argmax(predicao[0])\n",
    "confianca = predicao[0][classe_predita]\n",
    "\n",
    "# Visualiza\n",
    "plt.figure(figsize=(6, 6))\n",
    "plt.imshow(imagem[0].squeeze(), cmap='gray')\n",
    "plt.title(f'Real: {class_names[label_real]}\\nPredição: {class_names[classe_predita]} ({confianca:.2%})')\n",
    "plt.axis('off')\n",
    "plt.show()\n",
    "\n",
    "# Mostra probabilidades para todas as classes\n",
    "print(\"\\nProbabilidades por classe:\")\n",
    "for i, prob in enumerate(predicao[0]):\n",
    "    print(f\"  {class_names[i]}: {prob:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experimentos Adicionais\n",
    "\n",
    "### 1. Teste com Diferentes Arquiteturas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Experimento: Modelo mais profundo\n",
    "from tensorflow.keras import layers, models\n",
    "\n",
    "def criar_modelo_profundo(input_shape, num_classes):\n",
    "    \"\"\"Modelo CNN mais profundo para experimentação\"\"\"\n",
    "    model = models.Sequential([\n",
    "        # Bloco 1\n",
    "        layers.Conv2D(32, (3, 3), activation='relu', input_shape=input_shape, padding='same'),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.Conv2D(32, (3, 3), activation='relu', padding='same'),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.MaxPooling2D((2, 2)),\n",
    "        layers.Dropout(0.25),\n",
    "        \n",
    "        # Bloco 2\n",
    "        layers.Conv2D(64, (3, 3), activation='relu', padding='same'),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.Conv2D(64, (3, 3), activation='relu', padding='same'),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.MaxPooling2D((2, 2)),\n",
    "        layers.Dropout(0.25),\n",
    "        \n",
    "        # Camadas densas\n",
    "        layers.Flatten(),\n",
    "        layers.Dense(128, activation='relu'),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.Dropout(0.5),\n",
    "        layers.Dense(num_classes, activation='softmax')\n",
    "    ])\n",
    "    \n",
    "    return model\n",
    "\n",
    "# Testa o modelo profundo\n",
    "modelo_profundo = criar_modelo_profundo(input_shape, num_classes)\n",
    "modelo_profundo.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Data Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cria pipeline de aumento de dados\n",
    "from data_loader import criar_data_augmentation\n",
    "\n",
    "data_aug = criar_data_augmentation()\n",
    "\n",
    "# Visualiza efeitos do aumento de dados\n",
    "fig, axes = plt.subplots(2, 4, figsize=(12, 6))\n",
    "axes = axes.ravel()\n",
    "\n",
    "# Pega uma imagem\n",
    "img = x_train_prep[0:1]\n",
    "\n",
    "for i in range(8):\n",
    "    if i == 0:\n",
    "        axes[i].imshow(img[0].squeeze(), cmap='gray')\n",
    "        axes[i].set_title('Original')\n",
    "    else:\n",
    "        augmented = data_aug(img)\n",
    "        axes[i].imshow(augmented[0].numpy().squeeze(), cmap='gray')\n",
    "        axes[i].set_title(f'Aumentada {i}')\n",
    "    axes[i].axis('off')\n",
    "\n",
    "plt.suptitle('Efeitos do Data Augmentation', fontsize=16)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Como Adaptar para Outros Problemas\n",
    "\n",
    "### 1. Para usar seus próprios dados:\n",
    "\n",
    "```python\n",
    "# Carregue suas imagens\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
    "import glob\n",
    "\n",
    "# Exemplo: carregar imagens de uma pasta\n",
    "def carregar_imagens_pasta(pasta, tamanho=(28, 28)):\n",
    "    imagens = []\n",
    "    labels = []\n",
    "    \n",
    "    for classe, nome_classe in enumerate(os.listdir(pasta)):\n",
    "        caminho_classe = os.path.join(pasta, nome_classe)\n",
    "        for img_path in glob.glob(f\"{caminho_classe}/*.jpg\"):\n",
    "            img = load_img(img_path, target_size=tamanho, color_mode='grayscale')\n",
    "            img_array = img_to_array(img)\n",
    "            imagens.append(img_array)\n",
    "            labels.append(classe)\n",
    "    \n",
    "    return np.array(imagens), np.array(labels)\n",
    "```\n",
    "\n",
    "### 2. Para problemas de regressão:\n",
    "\n",
    "```python\n",
    "# Mude a última camada e a função de perda\n",
    "model.add(layers.Dense(1))  # Sem ativação para regressão\n",
    "model.compile(loss='mse', metrics=['mae'])\n",
    "```\n",
    "\n",
    "### 3. Para detecção de objetos ou segmentação:\n",
    "\n",
    "- Use arquiteturas específicas como YOLO, R-CNN (detecção)\n",
    "- Use U-Net, SegNet (segmentação)\n",
    "- Adapte o carregamento de dados para incluir bounding boxes ou máscaras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Recursos Adicionais\n",
    "\n",
    "1. **TensorFlow Datasets**: Biblioteca com muitos datasets prontos\n",
    "   ```python\n",
    "   import tensorflow_datasets as tfds\n",
    "   ds_train, ds_test = tfds.load('mnist', split=['train', 'test'])\n",
    "   ```\n",
    "\n",
    "2. **Transfer Learning**: Use modelos pré-treinados\n",
    "   ```python\n",
    "   base_model = tf.keras.applications.VGG16(\n",
    "       input_shape=(224, 224, 3),\n",
    "       include_top=False,\n",
    "       weights='imagenet'\n",
    "   )\n",
    "   ```\n",
    "\n",
    "3. **Callbacks Customizados**: Crie seus próprios callbacks\n",
    "   ```python\n",
    "   class MeuCallback(tf.keras.callbacks.Callback):\n",
    "       def on_epoch_end(self, epoch, logs=None):\n",
    "           print(f\"Época {epoch} concluída!\")\n",
    "   ```"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}